\section{Methods}

\red{ What we are doing in this paper}
The Wendling model is capable of replicating key features of observed in hippocampal EEG prior to, during and post seizure~\citep{wendling2002epileptic}. Here the estimation of physiologically relevant model parameters from the Wendling model is considered. An unscented Kalman filter is used to estimate the model parameters of interest. For this study the estimation procedure is tested using artificial EEG simulated using the Wendling model. By doing so it is possible to determine how robust the unscented Kalman filter is when estimating the Wendling model.

\subsection{Model Description and Simulation}

\red{Wendling model description.}

The Wendling model describes the aggregate membrane potentials and firing rates produced by different neural populations. The populations are then excited or inhibited by other populations in the model. The net effect of one population on another is determined by a scaling constant termed the connectivity constant. A graphical representation of the model is shown in Figure~\ref{fig: Biological}. In the model four different neural populations are considered. The pyramidal neural population is the generator of the model output, and its aggregate membrane potential is the simulated artificial EEG. Excitatory interneurons excite the pyramidal neurons. Slow and fast inhibitory interneurons inhibit the pyramidal neural population. Further, the pyramidal neural population excites the excitatory, slow and fast inhibitory populations. Lastly, slow inhibitory interneurons inhibit the fast inhibitory neural population. The effect of each neural population on the other is scaled by a connectivity constant. This connectivity constant accounts for the number of neurons within each population.  Lastly, a stochastic input to the model is added to account for the effect of afferent pyramidal neurons on the modeled neural mass.
\begin{figure}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\centering
		\includegraphics{jpg/Biological_Model_Description.jpg}
	\caption{Graphical Descption of the Wendling model.}
	\label{fig: Biological}
\end{figure}

\red{Mathematical functions used in the model}
The Wendling model consists of two primary structures. The first structure is a sigmoid function which converts an aggregate membrane potential to an average firing rate (Equation~\ref{eqn: Sigmoid}). In equation~\ref{eqn: Sigmoid} $g(v(t))$ is the firing rate, $g_{max}$ is the maximum firing rate, $r$ is the sigmoid gradient and $v_{0}$ is the membrane potential at which $0.5g_{max}$ is reached. The second structure is an average firing rate to aggregate membrane potential kernel (Equations~\ref{eqn: Convert}-\ref{eqn: Kernel}). In equations~\ref{eqn: Convert}-\ref{eqn: Kernel} $v_k(t)$ is the aggregate membrane potential, $h_{k}(t)$ is kernel which converts firing rates into membrane potentials, $\theta_{k}(t)$ is the synaptic gain and $\tau_{k}$ is the time constant. $h_{k}(t)$ is a delayed exponential decay function (Figure~\ref{fig: FR2PSP_final}).\begin{align}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{eqn: Sigmoid}
g(v(t)) = \frac{g_{max}}{1+exp(r(v(t)-v_{0}))}\\
\label{eqn: Convert}
v_{k}(t) = h_{k}(t)*g(v(t))\\
\label{eqn: Kernel} 
h_{k}(t) = \frac{\theta_{k}(t)}{\tau_{k}}texp\left(-\frac{t}{\tau_{k}}\right).
\end{align} Here the subscript $k$ is used to indicate that each neural population is described with a different synaptic gain and time constant. The synaptic gains are described by $\theta_{k}$ as they are the parameters that are altered in order to simulate artificial seizure EEG (Figure~\ref{fig: SeizureSim}). Further, the synaptic gains will be the variables that are estimated in this study. In this description of the Wendling model numerous model parameters are considered to be stationary, this includes the maximum firing rate~($g_{max}$) and time constants~($\tau_{k}$). 
\begin{figure}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\centering
		\includegraphics{pdf/FR2PSP_final.pdf}
	\caption{Firing rate to aggregate membrane potential converter.}
	\label{fig: FR2PSP_final}
\end{figure} 
\begin{figure}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\centering
		\includegraphics{../../Images/Images/pdf/Boon_SF_512_FO_10_HC_3_LC_100Wendling_Output.pdf}
	\caption{Artificial seizure simulated using the wendling model.}
	\label{fig: SeizureSim}
\end{figure}
Equations~\ref{eqn: Convert}-\ref{eqn: Kernel} can be converted into a set of two differential equations \begin{align}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{eqn: FR2PSP1}
\dot{v}_{k}(t)&= z_{k}(t)\\
\label{eqn: FR2PSP2}
\dot{z}_{k}(t)&=\frac{\theta_{k}(t)}{\tau_{k}}n_{k}u_{k}(t)-2\frac{z_{k}(t)}{\tau_{k}}-\frac{v_{k}(t)}{\tau_{k}^{2}}.
\end{align} Here $v_{k}(t)$ is the average membrane potential and $z_{k}(t)$ is its derivative. $\theta_{k}(t)$ and $\tau_{k}$ are the specific neural populations synaptic gain and time constant. Lastly, $u_{k}(t)$ is the firing rate to the specific neural population considered and $n_{k}$ is a constant used to specify connectivity.

\red{Full mathematical description of the model}
Using equations~\ref{eqn: FR2PSP1}-\ref{eqn: FR2PSP2} the model can be described by a set of eight stochastic differential equations \begin{align}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
dv_{po}(t)&= z_{po}(t)dt\\
dz_{po}(t)&=\left(\frac{\theta_{p}(t)}{\tau_{p}}n_{p}g(v_{p}(t))-2\frac{z_{po}(t)}{\tau_{p}}-\frac{v_{po}(t)}{\tau_{p}^{2}}\right)dt\\
dv_{eo}(t)&= z_{eo}(t)dt\\
dz_{eo}(t)&=\left(\frac{\theta_{e}(t)}{\tau_{e}}(\mu +n_{e}g(v_{e}(t))-2\frac{z_{eo}(t)}{\tau_{e}}-\frac{v_{eo}(t)}{\tau_{e}^{2}}\right)dt + \frac{\theta_{e}(t)}{\tau_{e}}\epsilon(t)dW\\
dv_{sio}(t)&= z_{sio}(t)dt\\
dz_{sio}(t)&=\left(\frac{\theta_{si}(t)}{\tau_{si}}n_{si}g(v_{si}(t))-2\frac{z_{sio}(t)}{\tau_{si}}-\frac{v_{sio}(t)}{\tau_{si}^{2}}\right)dt\\
dv_{fio}(t)&= z_{fio}(t)dt\\
dz_{fio}(t)&=\left(\frac{\theta_{fi}(t)}{\tau_{fi}}n_{fi}g(v_{fi}(t))-2\frac{z_{fio}(t)}{\tau_{fi}}-\frac{v_{fio}(t)}{\tau_{fi}^{2}}\right)dt.
\end{align} $dW$ represents a Wiener process and is required as $\epsilon(t)\longmapsto N(0,\sigma)$. Here $\sigma$ and $\mu$ describe the mean and variance of the stochastic model input. Further, $v_{ko}(t) $ and $z_{ko}(t) $ represent the membrane potential produced by each neural population. $v_{k}(t) $ and $z_{k}(t) $ are the inputs to each neural population, and are considered to be the membrane potential of the specific population. $k$ takes the values of $p$, $e$, $fi$ and $si$ representing pyramidal, excitatory, and slow and fast inhibitory populations, respectively. Therefore $v_{p}(t) $ is the output of the model. All $v_{k}(t) $ can be described in terms of $v_{ko}(t) $ as follows \begin{align}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
v_{p}(t) &= v_{eo}(t)-v_{sio}(t)-v_{fio}(t)\\
v_{e}(t) &= c_{1}v_{po}(t)\\
v_{si}(t) &= c_{3}v_{po}(t)\\
v_{fi}(t) &= c_{5}v_{po}(t)-c_{6}v_{sio}(t),
\end{align} where $c_{1}$, $c_{3}$ and $c_{5}$ represent the connectivity strength from pyramidal to excitatory, slow inhibitory and fast inhibitory populations, respectively. $c_{6}$ represents the connectivity strength from the slow to the fast inhibitory population. Lastly, all $n_{k}$ can be defined as connectivity constants \begin{align}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
n_{p} &=1\\
n_{e} &=c_{2}\\
n_{si} &=c_{4}\\
n_{fi} &=c_{7}.
\end{align} Here $c_{2}$, $c_4$ and $c_7$ represent the connectivity strength from excitatory, slow inhibitory and fast inhibitory to the pyramidal population.

\red{Simulation of model}
This set of continuous stochastic differential equations is discretised using Euler-Mariyama's method, to simulate the artificial EEG. \begin{align}
v_{po,t+T}&=v_{po,t}+Tz_{po,t}\\
z_{po,t+T}&=z_{po,t}+T\left(\frac{\theta_{p,t}}{\tau_{p}}n_{p}g(v_{p,t})-2\frac{z_{po,t}}{\tau_{p}}-\frac{v_{po,t}}{\tau_{p}^{2}}\right)\\
v_{eo,t+T}&=v_{eo,t}+Tz_{eo,t}\\
z_{eo,t+T}&=z_{eo,t}+T\left(\frac{\theta_{e,t}}{\tau_{e}}(\mu +n_{e}g(v_{e,t})-2\frac{z_{eo,t}}{\tau_{e}}-\frac{v_{eo,t}}{\tau_{e}^{2}}\right) + \sqrt{T}\frac{\theta_{e,t}}{\tau_{e}}\epsilon_{t}\\
v_{sio,t+T}&=v_{sio,t}+Tz_{sio,t}\\
z_{sio,t+T}&=z_{sio,t}+T\left(\frac{\theta_{si,t}}{\tau_{si}}n_{si}g(v_{si,t})-2\frac{z_{sio,t}}{\tau_{si}}-\frac{v_{sio,t}}{\tau_{si}^{2}}\right)\\
v_{fio,t+T}&=v_{fio,t}+Tz_{fio,t}\\
z_{fio,t+T}&=z_{fio,t}+T\left(\frac{\theta_{fi,t}}{\tau_{fi}}n_{fi}g(v_{fi,t})-2\frac{z_{fio,t}}{\tau_{fi}}-\frac{v_{fio,t}}{\tau_{fi}^{2}}\right).
\end{align} Here $T$ is the period between solutions. The static parameter values are demonstrated in  Tables~\ref{tab: Static}-\ref{tab: Connectivity}. The variance of the input ($\sigma$) is specified such that 99.7\% of realisations drawn from the Gaussian distribution fall within the specified maximum and minimum firing rate. In this case, the firing rate limits are set to 30 and 150. For the cases where the realisations from the Gaussian distribution are not contained within the limits specified, the specific sample of interest is redrawn from the same Gaussain distribution until the firing rate falls within the specified range. In Table~\ref{tab: Static} the parameters $\theta_{p,t}$, $\theta_{e,t}$, $\theta_{si,t}$ and $\theta_{fi,t}$ are not specified as these parameters will vary for different simulations. However,for this simulation it is assumed that \begin{align}
\theta_{p,t} = \theta_{e,t}.
\end{align}


\singlespacing
\small
\begin{center}
	\begin{table}
			\caption{Static Model Parameters}
		\begin{tabular}{||p{4cm}|p{6cm}|p{1.5cm}|p{1.2cm}||}\hline
			 \textsc{Model parameter}  & \textsc{Physical description} & \textsc{Value} & \textsc{Units}  \\\hline\hline
			 $\tau_{p}$ & Time constant for pyramidal neurons & 100 & $s^{-1}$\\\hline
			 $\tau_{e}$ & Time constant for excitatory neurons & 100 & $s^{-1}$\\\hline
			 $\tau_{si}$ & Time constant for slow inhibitory neurons & 35 & $s^{-1}$\\\hline
			 $\tau_{fi}$ & Time constant for fast inhibitory neurons & 500 & $s^{-1}$\\\hline
			 $c$ & Connectivity constant & 135 & NA\\\hline
			 $g_{max}$ & Maximum firing rate & 5 & Hz \\\hline
			 $v_{0}$ & PSP for which 50\% firing rate is achieved & 6 & $mV^{-1}$\\\hline
			 $r$ & Gradient of sigmoid function & 0.56 & NA \\\hline
			 $\mu$ & Input mean firing rate & 90 & $Hz$\\\hline
			 $\sigma$ & Variance of input firing rate & 15 & $Hz$\\\hline\hline 
		\end{tabular}
		\label{tab: Static}
	\end{table}
\end{center}

\begin{center}
	\begin{table}
			\caption[Static Model Parameters: Connectivity]{Static model parameters: Connectivity. $C$ is the connectivity constant specified in Table~\ref{tab: Static}. Terms in brackets indicate the direction in which the constant affects the system. Here P, E, SI and FI represent populations of pyramidal neurons and excitatory, slow inhibitory and fast inhibitory interneurons, respectively.}
		\begin{tabular}{||p{4cm}|p{7cm}|p{2cm}||}\hline
			 \textsc{Model parameter}  & \textsc{Physical description} & \textsc{Value}
			   \\\hline\hline
			 $c_{1}$ & Connectivity constant (P - E) & $C$ \\\hline
			 $c_{2}$ & Connectivity constant (E + I - P) & $0.8C$ \\\hline
			 $c_{3}$ & Connectivity constant (P - SI) & $0.25C$  \\\hline
			 $c_{4}$ & Connectivity constant (SI - P)& $0.25C$ \\\hline
			 $c_{5}$ & Connectivity constant (P - FI) & $0.3C$ \\\hline
			 $c_{6}$ & Connectivity constant (SI - FI) & $0.1C$ \\\hline
			 $c_{7}$ & Connectivity constant (SI - P) & $0.8C$ \\\hline\hline
		\end{tabular}
		\label{tab: Connectivity}
	\end{table}
\end{center}

\subsection{Estimation}

\red{Generic description on a nonlinear system}
To begin we define a generic nonlinear system where \begin{align}
\mathbf{\dot{x}}(t) = \mathbf{A}(\mathbf{x}(t),\mathbf{\theta}(t)) + \mathbf{B}(\mathbf{u}(t)) + \mathbf{n}(t)
\mathbf{y}(t)  = \mathbf{C}(\mathbf{x}(t)) +\mathbf{r}(t),
\end{align} with $x(t)$ the state vector and $\dot{x}(t)$ its derivative where
\[ \dot{x}(t) = \left[ \begin{array}[pos]{c}
\dot{x}_{1}(t)\\
\vdots \\
\dot{x}_{n}(t) \end{array} \right] .\]  $\mathbf{A}$, $\mathbf{B}$ and $\mathbf{C}$ are the state, input and output matrices and $u(t)$ the input to the model. $\mathbf{y}(t)$ is the model output with $\mathbf{n}(t)$ the model noise, or uncertainty and $\mathbf{r}(t)$ the measurement error, or observation noise. Here $\mathbf{n}(t)$ takes into account that the model is not a perfect descriptor of the particular region of the brain, and $\mathbf{r}(t)$ describes the maximum amplitude of the noise in the observations. Both $\mathbf{n}(t)$ and $\mathbf{r}(t)$ are zero mean Gaussian distributions with a system dependant variance. It is important to note that this assumption of a Gaussian distribution is only valid when the number of samples for the estimation procedure is large.

\red{Introduction to the UKF}
Estimation is usually performed to estimate the model states $x(t)$ given some observation $y(t)$ . One method that is often use for estimation linear systems in the Kalman filter. The Kalman filter consists of two steps: prediction and correction. In the prediction step model states are propagated through the system in order to give an estimate of the expected value of the states at the next time step. Using a first order Euler-Maruyama method this can be described by \begin{align}
\mathbf{x}_{t+T}^{-} = \mathbf{x}_{t} + T\mathbf{A}(\mathbf{x}_{t}) +\sqrt{T}\mathbf{n}_{t}
\label{eqn: YProp}
\mathbf{y}_{t+T}^{-}  = \mathbf{y}_{t} + T\mathbf{C}(\mathbf{y}_{t}) +\sqrt{T}\mathbf{r}_{t}
\end{align} where the subscript in $x_{t}^{-}$ is used to indicate a discrete time description and $T$ is the sampling period. The superscript in $x_{t}^{-}$ is used to indicate that this estimate is a prediction that has not yet been corrected by the current observation. Performing this kind of prediction for a nonlinear system would be inaccurate. The reason for this is that propagation of states like this in a system would require the assumption that the error in the states remains constant for all time. However, in a nonlinear system this is not true, as states error can vary drastically across time steps. In other words if the original state estimate is incorrect in a nonlinear system it is possible that the error can increase from one step to the next, which is not the case for  linear system. In order to account for this error, or state covariance changing an unscented filter is used in the prediction step for nonlinear systems. The advantage of an unscented filter over local linearisation techniques is both speed is improved and discontinuities can still be modeled. 

\red{The unscented filter}
The unscented filter is completely described by the states mean and covariance such that we can draw sigma points that are defined as  \begin{align}
\label{eqn: Unscented_Transform1}
\mathbf{\mathcal{x}}_{n} &= \mathbf{\overline{x}}_{t} + (\sqrt{\kappa+D_{x}\mathbf{P_{xx,t}}})_{n} \quad n=1,\hdots,D_x\\
\label{eqn: Unscented_Transform2}
\mathbf{\mathcal{x}}_{n+D_{x}} &= \mathbf{\overline{x}}_{t} - (\sqrt{\kappa+D_{x}\mathbf{P_{xx,t}}})_{n} \quad n=1,\hdots,D_x,
\end{align} where $\mathbf{\overline{x}}_{t}$ is the current state estimate. $\sqrt{\cdot}_{n}$ denotes the $n$th row or column of the matrix square root. $D_{x}$ is the number of states in the system and $\mathbf{P_{xx,t}}$ is the covariance matrix or expected error of the current state estimate. $\kappa$ is a predefined constant which determine the relative effect of the propagation of the mean. For now if $\kappa$ is equal to zero than the system mean is not propagated as a sigma point. However, if $\kappa$ is greater than zero then \begin{align}
\mathbf{\mathcal{X}}_{0} &= \mathbf{\overline{x}}_{t}.
\end{align} Now their are 2$D_{x}$ sigma points when $\kappa$ is zero or 2$D_{x}$+1 sigma points when it is greater than zero. These sigma points are then propagated through the system in oder to update the expectation about the state mean and error. \begin{align}
\mathbf{\mathcal{x}}_{n,t+T} &= \mathbf{\mathcal{x}}_{t}+ T\mathbf{A}(\mathbf{\mathcal{x}}_{n,t}) +\sqrt{T}{n}_{t}\\
\overline{\mathbf{x}}_{t+T}^{-} &= \frac{1}{2D_{x}+\kappa}\sum_{n=1}^{2D_{x}} \mathbf{\mathcal{x}}_{n,t+T}\\
\mathbf{P}_{xx,t+T}^{-} &= \frac{1}{2D_{x}+\kappa}\sum_{n=1}^{2D_{x}} (\mathbf{\mathcal{x}}_{n,t+T} -\mathbf{\overline{x}}_{t+T}^{-})(\mathbf{\mathcal{x}}_{n,t+T}-\mathbf{\overline{x}}_{t+T}^{-})^{\top} \mathbf{Q}.
\end{align} Here $\overline{\mathbf{x}}_{t+T}^{-}$ and $\mathbf{P}_{xx,t+T}^{-}$ are the predictions for the state and state covariance matrices. The superscript $a^{-}$ is used to indicate an uncorrected prediction. $\mathbf{Q}$ is the expectation of the model error $n_{t}$. Further, it is possible to make a prediction about the observation at time $t+T$ by propagating the sigma points through equation~\ref{eqn: YProp} \begin{align} 
\mathbf{\mathcal{y}}_{n,t+T} &= \mathbf{\mathcal{y}}_{t} + T\mathbf{C}(\mathbf{\mathcal{x}}_{n,t})+ \sqrt{T}{r}_{t}\\
\overline{\mathbf{y}}_{t+T}^{-} &= \frac{1}{2D_{x}+\kappa}\sum_{n=1}^{2D_{x}} \mathbf{\mathcal{y}}_{n,t+T}\\
\label{eqn: statecovg}
\mathbf{P}_{xy,t+T}^{-} &= \frac{1}{2D_{x}+\kappa}\sum_{n=1}^{2D_{x}} (\mathbf{\mathcal{x}}_{n,t+T}-\mathbf{x}_{n,t+T}) (\mathbf{\mathcal{y}}_{n,t+T}-\overline{\mathbf{y}}_{t+T}^{-})^{\top}\\
\mathbf{P}_{yy,t+T}^{-} &= \frac{1}{2D_{x}+\kappa}\sum_{n=1}^{2D_{x}} (\mathbf{\mathcal{y}}_{n,t+T}-\overline{\mathbf{y}}_{t+T}^{-}) (\mathbf{\mathcal{y}}_{n,t+T}-\overline{\mathbf{y}}_{t+T}^{-})^{\top} +\mathbf{R},
\end{align} where $\overline{\mathbf{y}}_{t+T}^{-}$ and $\mathbf{P}_{yy,t+T}^{-}$ are the predictions for the model output and its covariance. $\mathbf{P}_{xy,t+T}^{-}$ is the covariance matrix of the states and observations. Lastly, $\mathbf{R}$ is the expectation of the observation error $r_{t}$.

\red{How states are predicted using the unscented transform}
The predictions of the states ($\overline{\mathbf{x}}_{t+T}^{-}$) and observations ($\overline{\mathbf{y}}_{t+T}^{-}$) now need to be corrected based on the observations. This is achieved by \begin{align}
\mathbf{K} &= \mathbf{P}_{xy,t+T}^{-}(\mathbf{P}_{yy,t+T}^{-})^{-1}\\
\mathbf{x}_{t+T} &= \overline{\mathbf{x}}_{t+T}^{-} + \mathbf{K}(\mathbf{y}_{t+T}-\overline{\mathbf{y}}_{t+T}^{-})\\
\mathbf{P}_{xx,t+T} &= \mathbf{P}_{xx,t+T}^{-} - \mathbf{K}(\mathbf{P}_{xy,t+T}^{-})^{\top},
\end{align} where $\mathbf{y}_{t}$ is the recording or observation made, $\mathbf{x}_{t+T}$ is estimate of the state and $\mathbf{P}_{xx,t+T}$ is the estimate of the error on the state. This set of equations describes the UKF and how it can be used to estimate states. However, for this study estimation of states and parameters needs to be achieved (dual estimation).

\red{Definition of slow state matrix and its dynamics}
Firstly, reconsider the extended neural mass model. The parameters that are being estimated are $\theta_{p}$, $\theta_{e}$, $\theta_{si}$ and $\theta_{fi}$. Here it is assumed that \begin{align}
\theta_{p} = \theta_{e}.
\end{align} Therefore, three parameters need to be estimated, and a parameter matrix is defined
\[ \mathbf{\theta}_{t} = \left[ \begin{array}[pos]{c}
\theta_{p,t}\\
\theta_{si,t} \\
\theta_{fi,t} \end{array} \right] .\] This parameter matrix is then augmented to the original state matrix
\[ \mathbf{x}_{t} = \left[ \begin{array}[pos]{c}
\mathbf{x}_{t}\\
\mathbf{\theta}_{t} \end{array} \right] .\] Note that parameters will now be referred to as slow states, to allow for ease of reference to the newly defined state matrix. The next issue to consider is the description of the dynamics for the slow states. Due to the prediction correction steps of the unscented Kalman filter these slow states can be assigned trivial dynamics such that
\begin{align}
\label{eqn: parameterdynamics}
\mathbf{\theta}_{t+T} = \mathbf{\theta}_{t} + \mathbf{\eta_{t}}\\
E(\mathbf{\theta}_{t+T}) = \mathbf{\theta}_{t}\\
P_{\mathbf{\theta} \mathbf{\theta,t+T}} = \mathbf{\Psi},
\end{align} where $E(\cdot)$ is the expectation function and $\mathbf{\eta}_{t}\longmapsto N(0,\mathbf{\sigma})$.

\red{Intialisation of UKF for stationary parameters}
When initialising the unscented Kalman filter the uncertainty and standard deviation of the model needs to be specified. Initial estimations are performed under the assumption that the model's slow states are stationary. This assumption allows the uncertainty in slow states to be minimal. The reason for this being that this uncertainty in this case describes only model inaccuracy and not the trivial dynamics of the slow states. Standard deviations in the estimation description are described such that one standard deviation from the midpoint of the specified states range encompasses all possible values for the particular state. Further to this the uncertainty of states directly affected by the stochastic model input is increased to account for the randomness of this signal when simulating. This is required as a stochastic process such as this cannot, at present, be estimated accurately. 

\red{Intialisation of UKF for varying parameters}
Secondly, estimation of varying slow states required the addition of the trivial dynamics described in equation~\ref{eqn: parameterdynamics}. It is assumed that the uncertianty of the model error and slow state dynamics are additive.

\red{Estimation of model input mean}
Lastly, estimation of the stochastic inputs mean to the neural mass is considered. In order to achieve this it is assumed that the model input mean can be assumed to be varying slowly, similarly to the model's slow states. By doing so the input mean can be augmented to the state matrix and assigned trivial dynamics. 

\red{UKF estimation bounds and initialsation of states}
When performing estimation, the results on the model's slow states are bounded by their physiological range as specified by \cite{wendling2002epileptic}. Further, the initial estimate of the model states is described as a Gaussian with the mean specified as the midpoint of the states range and the standard deviation set such that 99.9\% of realisations are within the specified physiolgical range of the specific state. 

\red{Robustness test}
To determine how robust the estimation procedure is the effect of noise and varying initialisations of the model states are considered. Further, the ability of the estimation procedure to estimate varying slow states, with different rates of change is determined. 





%The estimation method used was originally described by Kalman, and later developed by Ulah for nonlinear parameter estimation.
%
%The method developed by Ulah makes use of two structures, and unscented transform to allow the nonlinearity of the model to be retained and the kalman update process to update the states and parameters based on observations.
%
%To allow for parameter estimation the parameters of interest are considered to be slow states. That being they vary slowly compared to the model states.
%
%These states are therefore augmented to the normal state matrix.
%
%The unscented transform is described by the following set of equations.
%
%The variable describes the standard deviation of the parameter.
%
%The square root function is a matrix square root, which is achieved using the cholesky matrix decomposition.
%
%The resultant covariance and mean and then described using the following set of equations.
%
%Note that similar to the unscented transform there are weights assigned to particular iterations of the unscented process. This allows the process to specify more or less weight on the propogation of the mean through the model.
%
%Once the covariances and means are determined the model states are updated using the standard kalman filter correction step. 
%
%The equations for the kalman update process are.
%
%Here the variable describes the expected observation noise, and variable y the uncertainty in the model.
%
%Here the observation is the output of the simulated signal.
%
%This uncertainty in the model is used to account for errors induced due to model assumptions.
%
%To determine the accuracy of the estimation process the normalised mean square error of the parameter and state estimates are determined.
%
%This estimation procedure is dependant on the original guess for the model parameters and states.
%
%To make the distance between the actual and initial guess of the state estimates the initial guess is set to the middle of the physiological range specified for each parameter. Standard deviation set to encompass the entire physiological range.
%
%A similar process is done for state guess and standard deviation, equations are...
%
%Model uncertianty is set low. And increased when parameters vary within a single simulation. This allows the parameters to track as their standard deviation decreases over periods when the model tracks well and if uncertainty is low these parameters will not be able to track the actual values precise;y.
%
%To determine the accuracy of the estimation procedure, the initial parameter guess is altered based on percentage from the actual.
%
%Observation noise is increased to determine limits on noise allowable for the model.
%
%Model parameters simulated are altered to determine the effect of the parameters on estimation.
%
%Model parameters are varied within single simulation to determine whether the estimaton procedure can track the varying parameters.
%
%
% Following this the simulations from the extended neural mass model will be presented.
%line
%
%
